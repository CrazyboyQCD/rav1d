//! The [`CaseSet`] API below is a safe and simplified version of the `case_set*` macros in `ctx.h`.
//!
//! The `case_set*` macros themselves replaced `memset`s in order to further optimize them
//! (in e3b5d4d044506f9e0e95e79b3de42fd94386cc61).
//! They appear optimized to work on short `memset`s,
//! where they do aligned writes of larger integers up to `u64` through aliasing `union`s.
//! Curiously, they seem to multiply every byte by 1, and I'm still not sure the point of that.
//!
//! The optimizations that I see in the `case_set*` macros that I considered preserving are mainly:
//! * larger, inlinable writes for small power of 2 lengths
//! * aligned writes for the above
//!
//! The other main optimization in that commit was to 8-byte align the fields of [`BlockContext`],
//! which would make writes into them 8-byte aligned,
//! and may lead to better cache boundary alignment.
//!
//! The former is easy to preserve in Rust, but the latter is difficult to do so without overhead,
//! as unaligned writes are UB, and so we'd need to at runtime check if they're aligned
//! (a runtime-determined `off`set is used, so we can't reasonably ensure this at compile-time).
//! That said, the assembly generated by the [`small_memset`] version for `x86` and `x86_64`
//! appear to at least be largely the same (or more optimized for the larger than `u64` cases),
//! so I'm not sure this matters.
//!
//! I assume that the original `case_set*` code was written this convoluted way for some reason
//! (there aren't any explanatory comments in the code or commits explaining the optimization decisions),
//! so I wanted to preserve as much of it as reasonably possible.
//! Thus, I've preserved the cases for the small power of 2 lengths,
//! rather than just calling [`slice::fill`], which compiles to a call to `libc`'s `memset`.
//!
//! To more thoroughly check this, I did some basic benchmarks,
//! the same benchmarks done in e3b5d4d044506f9e0e95e79b3de42fd94386cc61,
//! which introduced the `case_set*` macros.
//! That is, I benchmarked
//!
//! ```sh
//! cargo build --release && hyperfine './target/release/dav1d -i ./tests/large/chimera_8b_1080p.ivf -l 1000 -o /dev/null'
//! ```
//!
//! for 3 implementations:
//! * the original `case_set*` macros translated directly to `unsafe` Rust `fn`s
//! * the safe [`CaseSet`] implementation below using [`small_memset`] with its small powers of 2 optimization
//! * a safe [`CaseSet`] implementation using [`slice::fill`]/`memset` only
//!
//! When benchmarked on `x86_64-unknown-linux-gnu` with a 24 thread Ryzen 9 5900x,
//! the [`small_memset`] version was ~1.27% faster than the `case_set*` one,
//! and ~3.26% faster than the `memset` one.
//! The difference between the `case_set*` and `memset` implementations (~1.95%)
//! is similar to the difference documented in e3b5d4d044506f9e0e95e79b3de42fd94386cc61, which was 1.67%.
//! Given this, it seems clear that the `memset` option is the slowest in both C and Rust,
//! and since it was replaced with `case_set*` in C, we shouldn't use it in Rust.
//! Thus, the chosen [`small_memset`] implementation,
//! which is even faster than the naively ported `case_set*` implementation,
//! seems optimal, as it:
//! * is the fastest of the Rust implementations
//! * is completely safe
//! * employs the same small powers of 2 optimization the `case_set*` implementation did
//! * is far simpler than the `case_set*` implementation, consisting of a `match` and array writes
//!
//! One would assume that the `memset` implementation would employ similar optimizations,
//! and it may do so, but it is not inlinable, and perhaps this is the reason
//! it performs worse in the benchmarks in both C and Rust.
//!
//! [`BlockContext`]: crate::src::env::BlockContext

use std::iter::zip;

/// Perform a `memset` optimized for lengths that are small powers of 2.
///
/// For power of 2 lengths `<= UP_TO`,
/// the `memset` is done as an array write of that exactly (compile-time known) length.
/// If the length is not a power of 2 or `> UP_TO`,
/// then the `memset` is done by [`slice::fill`] (a `memset` call) if `WITH_DEFAULT` is `true`,
/// or else skipped if `WITH_DEFAULT` is `false`.
///
/// This optimizes for the common cases where `buf.len()` is a small power of 2,
/// where the array write is optimized as few and large stores as possible.
#[inline]
pub fn small_memset<T: Clone + Copy, const UP_TO: usize, const WITH_DEFAULT: bool>(
    buf: &mut [T],
    val: T,
) {
    fn as_array<T: Clone + Copy, const N: usize>(buf: &mut [T]) -> &mut [T; N] {
        buf.try_into().unwrap()
    }
    match buf.len() {
        01 if UP_TO >= 01 => *as_array(buf) = [val; 01],
        02 if UP_TO >= 02 => *as_array(buf) = [val; 02],
        04 if UP_TO >= 04 => *as_array(buf) = [val; 04],
        08 if UP_TO >= 08 => *as_array(buf) = [val; 08],
        16 if UP_TO >= 16 => *as_array(buf) = [val; 16],
        32 if UP_TO >= 32 => *as_array(buf) = [val; 32],
        64 if UP_TO >= 64 => *as_array(buf) = [val; 64],
        _ => {
            if WITH_DEFAULT {
                buf.fill(val)
            }
        }
    }
}

pub struct CaseSetter<const UP_TO: usize, const WITH_DEFAULT: bool> {
    offset: usize,
    len: usize,
}

impl<const UP_TO: usize, const WITH_DEFAULT: bool> CaseSetter<UP_TO, WITH_DEFAULT> {
    #[inline]
    pub fn set<T: Clone + Copy>(&self, buf: &mut [T], val: T) {
        small_memset::<T, UP_TO, WITH_DEFAULT>(&mut buf[self.offset..][..self.len], val);
    }
}

/// The entrypoint to the [`CaseSet`] API.
///
/// `UP_TO` and `WITH_DEFAULT` are made const generic parameters rather than have multiple `case_set*` `fn`s,
/// and these are put in a separate `struct` so that these 2 generic parameters
/// can be manually specified while the ones on the methods are inferred.
pub struct CaseSet<const UP_TO: usize, const WITH_DEFAULT: bool>;

impl<const UP_TO: usize, const WITH_DEFAULT: bool> CaseSet<UP_TO, WITH_DEFAULT> {
    /// Perform one case set.
    ///
    /// This API is generic over the element type (`T`) rather than hardcoding `u8`,
    /// as sometimes other types are used, though only `i8` is used currently.
    ///
    /// The `len` and `offset` are supplied here and
    /// applied to each `buf` passed to [`CaseSetter::set`] in `set_ctx`.
    #[inline]
    pub fn one<T, F>(ctx: T, len: usize, offset: usize, mut set_ctx: F)
    where
        F: FnMut(&CaseSetter<UP_TO, WITH_DEFAULT>, T),
    {
        set_ctx(&CaseSetter { offset, len }, ctx);
    }

    /// Perform many case sets in one call.
    ///
    /// This allows specifying the `set_ctx` closure inline easily,
    /// and also allows you to group the same args together.
    ///
    /// The `lens`, `offsets`, and `dirs` are zipped and passed to [`CaseSet::one`],
    /// where `dirs` can be an array of any type and whose elements are passed back to the `set_ctx` closure.
    #[inline]
    pub fn many<T, F, const N: usize>(
        dirs: [T; N],
        lens: [usize; N],
        offsets: [usize; N],
        mut set_ctx: F,
    ) where
        F: FnMut(&CaseSetter<UP_TO, WITH_DEFAULT>, T),
    {
        for (dir, (len, offset)) in zip(dirs, zip(lens, offsets)) {
            Self::one(dir, len, offset, &mut set_ctx);
        }
    }
}
